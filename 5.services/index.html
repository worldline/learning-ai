<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.26" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const useChoice = localStorage.getItem('vuepress-color-scheme')
      const systemStatus =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (useChoice === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (useChoice === 'dark' || systemStatus) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"GenAI for services","image":[""],"dateModified":"2025-12-16T10:59:31.000Z","author":[]}</script><meta property="og:url" content="https://worldline.github.io/learning-ai/learning-ai/5.services/"><meta property="og:title" content="GenAI for services"><meta property="og:description" content="GenAI for services This section is dedicated to the usage of Generative AI models for services applications. We will explore how to interact with LLMs from simple REST API calls..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-12-16T10:59:31.000Z"><meta property="article:modified_time" content="2025-12-16T10:59:31.000Z"><link rel="icon" href="/learning-ai/favicon.ico"><link rel="manifest" href="/learning-ai/manifest.webmanifest"><meta name="theme-color" content="#00A67E"><meta name="mobile-web-app-capable" content="yes"><link rel="apple-touch-icon" href="/learning-ai/logo.png"><title>GenAI for services</title><meta name="description" content="GenAI for services This section is dedicated to the usage of Generative AI models for services applications. We will explore how to interact with LLMs from simple REST API calls...">
    <link rel="preload" href="/learning-ai/assets/style-ylIbZYxg.css" as="style"><link rel="stylesheet" href="/learning-ai/assets/style-ylIbZYxg.css">
    <link rel="modulepreload" href="/learning-ai/assets/app-DmbIGF3-.js"><link rel="modulepreload" href="/learning-ai/assets/index.html-DhySt__C.js">
    <link rel="prefetch" href="/learning-ai/assets/index.html-Zm4Bs2b8.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-CSX1SPNI.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-CYexrqkm.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-CtqQtP39.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-DN4qfUpI.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-Dg7YfMyW.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-BBuOJu-k.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-DSMPBn86.js" as="script"><link rel="prefetch" href="/learning-ai/assets/404.html-eQbHGPPb.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index-DTEEl-sV.js" as="script"><link rel="prefetch" href="/learning-ai/assets/katex-BXNjbZo7-DwZch6wb.js" as="script"><link rel="prefetch" href="/learning-ai/assets/dagre-SWNTG5WE-DSC1Q6c--tJStmTmP.js" as="script"><link rel="prefetch" href="/learning-ai/assets/c4Diagram-GPMAACGM-PJaXuOsG-D__CqRtM.js" as="script"><link rel="prefetch" href="/learning-ai/assets/flowDiagram-TSWR6T2D-Dul0xtMP-C_wb_pvE.js" as="script"><link rel="prefetch" href="/learning-ai/assets/flowDiagram-TSWR6T2D-Dul0xtMP-C_wb_pvE.js" as="script"><link rel="prefetch" href="/learning-ai/assets/erDiagram-WO52GFNT-DluJ77q3-C2mgQHFM.js" as="script"><link rel="prefetch" href="/learning-ai/assets/gitGraphDiagram-5C7YHVU6-o7rQLK0p-tfZGSifH.js" as="script"><link rel="prefetch" href="/learning-ai/assets/ganttDiagram-FAOCOTIY-QMiwl3Ii-BXGeVqty.js" as="script"><link rel="prefetch" href="/learning-ai/assets/infoDiagram-P5D6MX3V-BHt8SMCk-BzsL-xUt.js" as="script"><link rel="prefetch" href="/learning-ai/assets/pieDiagram-BLWKPB35-CtctdKjp-D4VztY9B.js" as="script"><link rel="prefetch" href="/learning-ai/assets/quadrantDiagram-QXWEEFXS-DatTgCl2-CtFKWk1s.js" as="script"><link rel="prefetch" href="/learning-ai/assets/xychartDiagram-MYLB5AYS-C-og51gq-BHstRROK.js" as="script"><link rel="prefetch" href="/learning-ai/assets/requirementDiagram-XAUNFCZY-DYsS1_Ym-Yjz3huVl.js" as="script"><link rel="prefetch" href="/learning-ai/assets/sequenceDiagram-D25TJ2OB-pKzEJHJE-CDno5ou-.js" as="script"><link rel="prefetch" href="/learning-ai/assets/classDiagram-FEGYTUDG-Ckev2IdL-CalNLXJM.js" as="script"><link rel="prefetch" href="/learning-ai/assets/classDiagram-v2-R65JCUOM-Ckev2IdL-CalNLXJM.js" as="script"><link rel="prefetch" href="/learning-ai/assets/stateDiagram-GNSP7T6Y-B3_6J16p-B0gWhQcE.js" as="script"><link rel="prefetch" href="/learning-ai/assets/stateDiagram-v2-HP6YRVRG-C7LWn7Of-CeN_JbV0.js" as="script"><link rel="prefetch" href="/learning-ai/assets/journeyDiagram-UIGPPNLY-CNXj_qEy-o_7AZuEl.js" as="script"><link rel="prefetch" href="/learning-ai/assets/flowDiagram-TSWR6T2D-Dul0xtMP-C_wb_pvE.js" as="script"><link rel="prefetch" href="/learning-ai/assets/timeline-definition-27KQCCZ3-CpKNx_hR-DoYIWrAX.js" as="script"><link rel="prefetch" href="/learning-ai/assets/mindmap-definition-R7LC4OIY-C2O8unyl-CkPxQdRx.js" as="script"><link rel="prefetch" href="/learning-ai/assets/kanban-definition-KMT3NSR2-CZuFpg4Z-ClAaYINY.js" as="script"><link rel="prefetch" href="/learning-ai/assets/sankeyDiagram-LVV36NHA-SibqQMmk-tS1p01PO.js" as="script"><link rel="prefetch" href="/learning-ai/assets/diagram-NZMEDLQF-BGsSdY7i-JtMH6xMb.js" as="script"><link rel="prefetch" href="/learning-ai/assets/blockDiagram-XN6IQ5JY-MzQvMLpX-EBvG3PZz.js" as="script"><link rel="prefetch" href="/learning-ai/assets/architectureDiagram-AYX4OTIS-1x9VSuVi-Ds5TJjSc.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/learning-ai/"><img class="vp-site-logo" src="/learning-ai/logo_worldline.png" alt><!----></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/worldline/learning-ai/activity" aria-label="‚≠ê See changelogs &amp; contribute" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!--]--><!--]-->‚≠ê See changelogs &amp; contribute<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><form class="search-box" role="search"><input type="search" placeholder="Search..." autocomplete="off" spellcheck="false" value><!----></form></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/worldline/learning-ai/activity" aria-label="‚≠ê See changelogs &amp; contribute" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!--]--><!--]-->‚≠ê See changelogs &amp; contribute<!--[--><!--[--><!--]--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/" aria-label="Home"><!--[--><!--[--><!--]--><!--]-->Home<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/1.intro/" aria-label="Introduction"><!--[--><!--[--><!--]--><!--]-->Introduction<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/2.prompt/" aria-label="Prompting usages"><!--[--><!--[--><!--]--><!--]-->Prompting usages<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/3.client/" aria-label="Online/Offline LLMs clients"><!--[--><!--[--><!--]--><!--]-->Online/Offline LLMs clients<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/4.assistant/" aria-label="Code Assistants in IDEs"><!--[--><!--[--><!--]--><!--]-->Code Assistants in IDEs<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item vp-sidebar-heading active" href="/learning-ai/5.services/" aria-label="GenAI for services"><!--[--><!--[--><!--]--><!--]-->GenAI for services<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/6.agentic/" aria-label="Agentic AI for services"><!--[--><!--[--><!--]--><!--]-->Agentic AI for services<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/7.node/" aria-label="Agentic AI node-based"><!--[--><!--[--><!--]--><!--]-->Agentic AI node-based<!--[--><!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/8.cloud/" aria-label="(Agentic AI on the cloud)"><!--[--><!--[--><!--]--><!--]-->(Agentic AI on the cloud)<!--[--><!--[--><!--]--><!--]--></a><!----></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div id="content"><h1 id="genai-for-services" tabindex="-1"><a class="header-anchor" href="#genai-for-services"><span>GenAI for services</span></a></h1><p>This section is dedicated to the usage of Generative AI models for services applications. We will explore how to interact with LLMs from simple REST API calls to more complex frameworks that enable context aware applications and agentic behaviors.</p><div class="hint-container tip"><p class="hint-container-title">Modalities for this training</p><ol><li>We will use <strong><a href="https://mistral.ai/" target="_blank" rel="noopener noreferrer">Mistral AI</a></strong> as the main LLM provider. Mistral AI provides free access to their models through REST APIs with a free tier making onboarding easy and fast.</li></ol><ul><li>You can sign up here : <a href="https://mistral.ai/signup" target="_blank" rel="noopener noreferrer">Mistral AI sign up</a></li><li>and get your API key from api keys section in your account settings here : <a href="https://console.mistral.ai/api-keys/" target="_blank" rel="noopener noreferrer">Mistral AI API keys</a>.</li></ul><ol start="2"><li><p>Also we choose <strong>Python</strong> as the main programming language for this training due to its popularity in the AI/ML community and the availability of up-to-date libraries and frameworks, documentations and easy onboarding.</p></li><li><p>We will use <strong><a href="https://colab.research.google.com/" target="_blank" rel="noopener noreferrer">Google Colab</a></strong> for an online use of jupyter notebooks. A notebook is an interactive environment for machine learning and data science. It is a single page document that contains both code and rich text elements (paragraphs, equations, figures, links, etc.) and allows you to run code in an interactive way. With a notebooks you can :</p></li></ol><ul><li>Prototype your ideas</li><li>Easily share your work with others</li><li>Collaborate with others</li><li>Gemini is pre-installed in Google Colab environments so you can code with ease even if you&#39;re not familiar with Python development.</li></ul><p><strong>NB: Please do not use, for now, Worldline email for connecting to Google Colab or you will have permission issues. If needed, create a dedicated Google account for that training.</strong></p></div><h3 id="google-colab-notebooks" tabindex="-1"><a class="header-anchor" href="#google-colab-notebooks"><span>Google Colab notebooks</span></a></h3><p><img src="/learning-ai/assets/colab-ChyULfJX.png" alt="Colab capture"></p><h4 id="store-api-keys" tabindex="-1"><a class="header-anchor" href="#store-api-keys"><span>Store API keys</span></a></h4><p>You can store secret keys such as API keys in the <code>userdata</code> of your Colab environment. To do so, follow these steps:</p><ol><li>Open the left sidebar in your Colab notebook.</li><li>Click on the &quot;Userdata&quot; tab (it looks like a key icon).</li><li>Click on the &quot;Add key&quot; button.</li><li>Enter a name for your key (e.g., <code>API_KEY</code>) and paste your API key in the value field.</li><li>Click &quot;Save&quot;.</li></ol><p>Now you can retrieve the API key in your Colab notebook as follows:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">from</span> google<span class="token punctuation">.</span>colab <span class="token keyword">import</span> userdata  <span class="token comment"># For retrieving API keys</span></span>
<span class="line"><span class="token comment"># get the API key from colab userdata ( left panel of colla, picto with the key)</span></span>
<span class="line">api_key<span class="token operator">=</span>userdata<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&#39;API_KEY&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="upload-files-in-colab" tabindex="-1"><a class="header-anchor" href="#upload-files-in-colab"><span>Upload files in Colab</span></a></h4><p>Also you can upload files to your Colab environment as follows:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">from</span> google<span class="token punctuation">.</span>colab <span class="token keyword">import</span> files</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 1. Upload the file to your current colab environment ( a upload button will appear at the execution of the code)</span></span>
<span class="line">uploaded <span class="token operator">=</span> files<span class="token punctuation">.</span>upload<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">for</span> fn <span class="token keyword">in</span> uploaded<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span></span>
<span class="line">        name<span class="token operator">=</span>fn<span class="token punctuation">,</span> length<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>uploaded<span class="token punctuation">[</span>fn<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 2. Now you can read the file as usual</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="importing-libraries" tabindex="-1"><a class="header-anchor" href="#importing-libraries"><span>Importing libraries</span></a></h4><p>To setup your Colab environment whith third party libraries, you can use the <code>pip</code> command directly in a code cell as follows:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line">!pip install <span class="token operator">&lt;</span>library<span class="token operator">-</span>name<span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>After clicking on the play button of the code cell, the library will be installed in your Colab environment and you can import it as usual in the next code cells.</p><h2 id="llms-with-rest-apis" tabindex="-1"><a class="header-anchor" href="#llms-with-rest-apis"><span>LLMs with REST APIs</span></a></h2><h4 id="openai-api-standard" tabindex="-1"><a class="header-anchor" href="#openai-api-standard"><span>OpenAI API standard</span></a></h4><p>OpenAI provides a set of standard endpoints for interacting with their LLMs. This standard is widely adopted by many LLM providers including Mistral AI. The main endpoints are as follows:</p><table><thead><tr><th>Endpoint &amp; Description</th><th>Method &amp; URL</th><th>Header</th><th>Body</th><th>Response</th></tr></thead><tbody><tr><td><strong>List Models</strong><br>Retrieve list of available models</td><td>GET <code>/v1/models</code></td><td><code>Authorization: Bearer {api_key}</code></td><td>‚Äî</td><td><code>{ &quot;object&quot;: &quot;list&quot;, &quot;data&quot;: [...], &quot;has_more&quot;: false }</code></td></tr><tr><td><strong>Retrieve Model</strong><br>Get details of a specific model</td><td>GET <code>/v1/models/{model}</code></td><td><code>Authorization: Bearer {api_key}</code></td><td>‚Äî</td><td><code>{ &quot;id&quot;: &quot;gpt-4&quot;, &quot;object&quot;: &quot;model&quot;, &quot;owned_by&quot;: &quot;openai&quot;, &quot;permission&quot;: [...], &quot;created&quot;: 1234567890 }</code></td></tr><tr><td><strong>Chat Completions</strong><br>Generate chat-based responses</td><td>POST <code>/v1/chat/completions</code></td><td><code>Authorization: Bearer {api_key}</code><br><code>Content-Type: application/json</code></td><td><code>{ &quot;model&quot;: &quot;gpt-4&quot;, &quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;...&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;...&quot;}], &quot;temperature&quot;: 0.7, &quot;max_tokens&quot;: 100, &quot;top_p&quot;: 1 }</code></td><td><code>{ &quot;id&quot;: &quot;chatcmpl-abc123&quot;, &quot;object&quot;: &quot;chat.completion&quot;, &quot;created&quot;: 1234567890, &quot;model&quot;: &quot;gpt-4&quot;, &quot;choices&quot;: [{ &quot;index&quot;: 0, &quot;message&quot;: {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;...&quot;}, &quot;finish_reason&quot;: &quot;stop&quot; }], &quot;usage&quot;: { &quot;prompt_tokens&quot;: 10, &quot;completion_tokens&quot;: 20, &quot;total_tokens&quot;: 30 } }</code></td></tr><tr><td><strong>Embeddings</strong><br>Generate vector embeddings for text</td><td>POST <code>/v1/embeddings</code></td><td><code>Authorization: Bearer {api_key}</code><br><code>Content-Type: application/json</code></td><td><code>{ &quot;model&quot;: &quot;text-embedding-3-small&quot;, &quot;input&quot;: &quot;Hello world&quot;, &quot;encoding_format&quot;: &quot;float&quot; }</code></td><td><code>{ &quot;object&quot;: &quot;list&quot;, &quot;data&quot;: [{ &quot;object&quot;: &quot;embedding&quot;, &quot;embedding&quot;: [0.123, -0.456, ...], &quot;index&quot;: 0 }], &quot;model&quot;: &quot;text-embedding-3-small&quot;, &quot;usage&quot;: { &quot;prompt_tokens&quot;: 3, &quot;total_tokens&quot;: 3 } }</code></td></tr></tbody></table><p>API references for Mistral AI :</p><ul><li><a href="https://docs.mistral.ai/api/#tag/models/operation/list_models_v1_models_get" target="_blank" rel="noopener noreferrer">Chat Endpoints - GET</a></li><li><a href="https://docs.mistral.ai/api/#tag/chat/operation/chat_completion_v1_chat_completions_post" target="_blank" rel="noopener noreferrer">Chat Endpoints - POST</a></li></ul><p>You can test these endpoints here:</p><div class="rest-llm-tester" data-v-11362d25><div class="config-section" data-v-11362d25><h3 data-v-11362d25>API Configuration</h3><div class="config-inputs" data-v-11362d25><div class="input-group" data-v-11362d25><label for="apiKey" data-v-11362d25>API Key:</label><input id="apiKey" value="" type="password" placeholder="Enter your Mistral AI API key" class="config-input" data-v-11362d25></div><div class="input-group" data-v-11362d25><label for="baseUrl" data-v-11362d25>Base URL:</label><input id="baseUrl" value="https://api.mistral.ai" type="text" placeholder="https://api.mistral.ai" class="config-input" data-v-11362d25></div></div></div><div class="endpoints-section" data-v-11362d25><h3 data-v-11362d25>Available Endpoints</h3><div class="endpoint-card" data-v-11362d25><div class="endpoint-header" data-v-11362d25><h4 data-v-11362d25><span class="method get" data-v-11362d25>GET</span> List Models</h4><p data-v-11362d25>Retrieve list of available models</p></div><button disabled class="test-button" data-v-11362d25> Test Endpoint </button></div><div class="endpoint-card" data-v-11362d25><div class="endpoint-header" data-v-11362d25><h4 data-v-11362d25><span class="method get" data-v-11362d25>GET</span> Retrieve Model</h4><p data-v-11362d25>Get details of a specific model</p></div><div class="input-group" data-v-11362d25><label data-v-11362d25>Model ID:</label><input value="open-mistral-7b" type="text" placeholder="open-mistral-7b" class="endpoint-input" data-v-11362d25></div><button disabled class="test-button" data-v-11362d25> Test Endpoint </button></div><div class="endpoint-card" data-v-11362d25><div class="endpoint-header" data-v-11362d25><h4 data-v-11362d25><span class="method post" data-v-11362d25>POST</span> Chat Completions</h4><p data-v-11362d25>Generate chat-based responses</p></div><div class="form-grid" data-v-11362d25><div class="input-group" data-v-11362d25><label data-v-11362d25>Model:</label><input value="open-mistral-7b" type="text" placeholder="open-mistral-7b" class="endpoint-input" data-v-11362d25></div><div class="input-group" data-v-11362d25><label data-v-11362d25>Temperature:</label><input value="0.7" type="number" min="0" max="2" step="0.1" class="endpoint-input" data-v-11362d25></div><div class="input-group" data-v-11362d25><label data-v-11362d25>Max Tokens:</label><input value="100" type="number" min="1" class="endpoint-input" data-v-11362d25></div><div class="input-group" data-v-11362d25><label data-v-11362d25>Top P:</label><input value="1" type="number" min="0" max="1" step="0.1" class="endpoint-input" data-v-11362d25></div></div><div class="input-group" data-v-11362d25><label data-v-11362d25>System Message:</label><textarea placeholder="You are a helpful assistant" class="endpoint-textarea" rows="2" data-v-11362d25>You are a helpful assistant.</textarea></div><div class="input-group" data-v-11362d25><label data-v-11362d25>User Message:</label><textarea placeholder="Hello, how are you?" class="endpoint-textarea" rows="3" data-v-11362d25></textarea></div><button disabled class="test-button" data-v-11362d25> Test Endpoint </button></div><div class="endpoint-card" data-v-11362d25><div class="endpoint-header" data-v-11362d25><h4 data-v-11362d25><span class="method post" data-v-11362d25>POST</span> Embeddings</h4><p data-v-11362d25>Generate vector embeddings for text</p></div><div class="input-group" data-v-11362d25><label data-v-11362d25>Model:</label><input value="mistral-embed" type="text" placeholder="mistral-embed" class="endpoint-input" data-v-11362d25></div><div class="input-group" data-v-11362d25><label data-v-11362d25>Input Text:</label><textarea placeholder="Hello world" class="endpoint-textarea" rows="2" data-v-11362d25></textarea></div><button disabled class="test-button" data-v-11362d25> Test Endpoint </button></div></div><div class="console-section" data-v-11362d25><div class="console-header" data-v-11362d25><h3 data-v-11362d25>Output Console</h3><button class="clear-button" data-v-11362d25>Clear</button></div><div class="console-output" data-v-11362d25><!--[--><!--]--><div class="console-empty" data-v-11362d25> Console output will appear here... </div></div></div></div><h4 id="structured-outputs" tabindex="-1"><a class="header-anchor" href="#structured-outputs"><span>Structured Outputs</span></a></h4><p><a href="https://platform.openai.com/docs/guides/structured-outputs" target="_blank" rel="noopener noreferrer"><code>Structured Outputs</code></a> is a feature that ensures the model will always generate responses that adhere to your supplied <a href="https://platform.openai.com/docs/api-reference/chat/create#chat_create-response_format" target="_blank" rel="noopener noreferrer">JSON Schema</a>, so you don&#39;t need to worry about the model omitting a required key, or hallucinating an invalid enum value.</p><p>Some benefits of Structured Outputs include:</p><ul><li>Reliable type-safety: No need to validate or retry incorrectly formatted responses</li><li>Explicit refusals: Safety-based model refusals are now programmatically detectable</li><li>Simpler prompting: No need for strongly worded prompts to achieve consistent formatting</li></ul><p>Structured Outputs is the evolution of <a href="https://docs.mistral.ai/capabilities/structured_output/json_mode" target="_blank" rel="noopener noreferrer"><code>JSON mode</code></a>. While both ensure valid JSON is produced, only Structured Outputs ensure schema adherence.</p><p><strong>Example</strong></p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">import</span> requests</span>
<span class="line"><span class="token keyword">import</span> json</span>
<span class="line"></span>
<span class="line">api_key <span class="token operator">=</span> <span class="token string">&quot;your-api-key&quot;</span></span>
<span class="line">url <span class="token operator">=</span> <span class="token string">&quot;https://api.openai.com/v1/chat/completions&quot;</span></span>
<span class="line"></span>
<span class="line">payload <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&quot;model&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;gpt-4&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&quot;messages&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">&quot;role&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;content&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Extract: John is 28 and lives in Paris&quot;</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&quot;response_format&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;json_schema&quot;</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token string">&quot;json_schema&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">            <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;person&quot;</span><span class="token punctuation">,</span></span>
<span class="line">            <span class="token string">&quot;schema&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                <span class="token string">&quot;type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;object&quot;</span><span class="token punctuation">,</span></span>
<span class="line">                <span class="token string">&quot;properties&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span></span>
<span class="line">                    <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">&quot;type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;string&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">                    <span class="token string">&quot;age&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">&quot;type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;integer&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">                    <span class="token string">&quot;city&quot;</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">&quot;type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;string&quot;</span><span class="token punctuation">}</span></span>
<span class="line">                <span class="token punctuation">}</span></span>
<span class="line">            <span class="token punctuation">}</span></span>
<span class="line">        <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">headers <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&quot;Authorization&quot;</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f&quot;Bearer </span><span class="token interpolation"><span class="token punctuation">{</span>api_key<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&quot;Content-Type&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;application/json&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token punctuation">,</span> json<span class="token operator">=</span>payload<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span></span>
<span class="line">result <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;choices&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;message&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&quot;content&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Output</strong></p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token punctuation">{</span><span class="token string">&#39;name&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;John&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;age&#39;</span><span class="token punctuation">:</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token string">&#39;city&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;Paris&#39;</span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="üß™-exercise" tabindex="-1"><a class="header-anchor" href="#üß™-exercise"><span>üß™ Exercise</span></a></h2><h4 id="request-an-llm-with-with-basic-rest-request" tabindex="-1"><a class="header-anchor" href="#request-an-llm-with-with-basic-rest-request"><span>Request an LLM with with basic REST request</span></a></h4><p>Create a Python application that generates humorous motivational quotes for developers based on their name, favorite programming language, and a brief description of their current project or challenge.</p><div class="hint-container tip"><p class="hint-container-title">Library for making API calls</p><p>You can use <a href="https://requests.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">requests</a> for making API calls in Python.</p></div><p><strong>Expected Output</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">Enter your name: Ibrahim</span>
<span class="line">Enter your favorite programming language: kotlin</span>
<span class="line">Enter your current project description: conference app with KMP</span>
<span class="line"></span>
<span class="line">--- Motivational Quote ---</span>
<span class="line">Quote: <span class="token string">&quot;Code like you just ate a burrito... with passion, speed, and a little bit of mess!&quot;</span></span>
<span class="line">Author: Unknown</span>
<span class="line">--------------------------</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">How to start ?</p><ul><li>Open the following <a href="https://colab.research.google.com/drive/1ZSQKYENLtjJqI7EvujcDS1O8SRvWq_n-#copy=true" target="_blank" rel="noopener noreferrer">Google Colab notebook</a> and complete the exercise there.</li></ul><p><strong>Steps</strong></p><ol><li>Create a function <code>get_developer_motivation(name, language, project_description)</code> that:</li><li>Takes a developer&#39;s name, their favorite programming language, and a brief description of their current project or challenge as input.</li><li>Uses the Mistral AI API to generate a humorous motivational quote. use request package to make the API call.</li><li>Returns a structured response containing the quote.</li></ol></div><div class="hint-container tip"><p class="hint-container-title">solution</p><details class="hint-container details"><summary>here</summary><p><a href="https://colab.research.google.com/drive/1rE_jC4DhD33Ni8MR9YTGK9WhykOTtbcF?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details></div><h2 id="context-aware-frameworks-langchain" tabindex="-1"><a class="header-anchor" href="#context-aware-frameworks-langchain"><span>Context aware frameworks (LangChain)</span></a></h2><p>LangChain is a framework for building applications powered by language models (LLMs) like OpenAI&#39;s GPT-3. It provides a set of tools and utilities for working with LLMs, including prompt engineering, chain of thought, and memory management. LangChain is designed to be modular and extensible, allowing developers to easily integrate with different LLMs and other AI services. Finally it enables to build agents and complex workflows on top of LLMs.</p><h3 id="request-llms" tabindex="-1"><a class="header-anchor" href="#request-llms"><span>Request LLMs</span></a></h3><h4 id="chat-models" tabindex="-1"><a class="header-anchor" href="#chat-models"><span>Chat models</span></a></h4><p>Depending on the LLM, LangChain provides different APIs that are called ChatModels. These models are designed to handle conversational interactions with the LLM, allowing you to send messages and receive responses in a chat-like format. Have a look at the following table <a href="https://python.langchain.com/docs/integrations/chat/" target="_blank" rel="noopener noreferrer">here</a> to see which APIs are available for your LLM.</p><p>Mistral AI Chat Model is supported by LangChain and provides the following features:</p><table><thead><tr><th>Model Features</th><th>Tool Calling</th><th>Structured Output</th><th>JSON Mode</th><th>Image Input</th><th>Audio Input</th><th>Video Input</th></tr></thead><tbody><tr><td></td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td><td>‚ùå</td><td>‚ùå</td><td>‚ùå</td></tr></tbody></table><p>To use langchain with mistral, you need to install the <code>langchain_mistralai</code> package and create a <code>ChatMistralAI</code> object.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">from</span> langchain_mistralai<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatMistralAI</span>
<span class="line"><span class="token comment"># Define your API key and model</span></span>
<span class="line">API_KEY <span class="token operator">=</span> <span class="token string">&#39;your_api_key&#39;</span>  <span class="token comment"># Replace with your actual Mistral API key</span></span>
<span class="line">MISTRAL_API_URL <span class="token operator">=</span> <span class="token string">&#39;https://api.mistral.ai/v1/chat/completions&#39;</span></span>
<span class="line">llm <span class="token operator">=</span> ChatMistralAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&quot;open-mistral-7b&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="prompt-template" tabindex="-1"><a class="header-anchor" href="#prompt-template"><span>Prompt template</span></a></h4><p><a href="https://reference.langchain.com/python/langchain_core/prompts/" target="_blank" rel="noopener noreferrer"><code>Prompt templating</code></a> is a powerful feature that allows you to create dynamic prompts based on the input data. It enables you to generate prompts that are tailored to the specific requirements of your application.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate</span>
<span class="line"></span>
<span class="line">prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span></span>
<span class="line">    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;language&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    template<span class="token operator">=</span><span class="token string">&quot;translate the following text to {language}: {text}&quot;</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="chaining" tabindex="-1"><a class="header-anchor" href="#chaining"><span>Chaining</span></a></h4><p><a href="https://python.langchain.com/v0.1/docs/modules/chains/" target="_blank" rel="noopener noreferrer"><code>Chain</code></a> Chains refer to sequences of calls - whether to an LLM, a tool, or a data pre-processing step. It is a sequence of calls that are executed in order, with the output of one call being the input for the next call.It enables you to create complex workflows by combining the output of one LLM call with the input of another. This is useful for tasks that require multiple steps or interactions with external systems.</p><p>Chains can be created using the <code>|</code> operator to combine different components, such as prompts and LLM models.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain</span>
<span class="line"></span>
<span class="line">input_data <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&quot;text&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Hello, how are you?&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&quot;language&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;French&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm_model</span>
<span class="line">response<span class="token operator">=</span>chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_data<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="aimessage" tabindex="-1"><a class="header-anchor" href="#aimessage"><span>AIMessage</span></a></h4><p><a href="https://docs.langchain.com/oss/python/langchain/messages#ai-message" target="_blank" rel="noopener noreferrer">AIMessage</a> represents the output of a model invocation. They can include multimodal data, tool calls, and provider-specific metadata that you can later access</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json"><pre><code class="language-json"><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;type&quot;</span><span class="token operator">:</span> <span class="token string">&quot;ai&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;content&quot;</span><span class="token operator">:</span> <span class="token string">&quot;The capital of France is Paris. It is located in northern-central France and is known for its iconic landmarks like the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum.&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;response_metadata&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token property">&quot;token_usage&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">      <span class="token property">&quot;completion_tokens&quot;</span><span class="token operator">:</span> <span class="token number">31</span><span class="token punctuation">,</span></span>
<span class="line">      <span class="token property">&quot;prompt_tokens&quot;</span><span class="token operator">:</span> <span class="token number">15</span><span class="token punctuation">,</span></span>
<span class="line">      <span class="token property">&quot;total_tokens&quot;</span><span class="token operator">:</span> <span class="token number">46</span></span>
<span class="line">    <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token property">&quot;model_name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;gpt-4&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token property">&quot;finish_reason&quot;</span><span class="token operator">:</span> <span class="token string">&quot;stop&quot;</span></span>
<span class="line">  <span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;id&quot;</span><span class="token operator">:</span> <span class="token string">&quot;run-abc123-xyz789&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token null keyword">null</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;example&quot;</span><span class="token operator">:</span> <span class="token boolean">false</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="output-parsers" tabindex="-1"><a class="header-anchor" href="#output-parsers"><span>Output Parsers</span></a></h4><p><a href="https://docs.langchain.com/oss/python/langchain/output_parsers/" target="_blank" rel="noopener noreferrer"><code>Output Parsers</code></a> are used to parse the output of an LLM into a structured format. They enable you to extract specific information from the LLM&#39;s response, making it easier to work with the data.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> JsonOutputParser</span>
<span class="line">output_parser <span class="token operator">=</span> JsonOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">response <span class="token operator">=</span> llm<span class="token punctuation">(</span><span class="token string">&quot;Generate a JSON object with name and age&quot;</span><span class="token punctuation">)</span></span>
<span class="line">parsed_output <span class="token operator">=</span> output_parser<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>response<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="üß™-exercise-1" tabindex="-1"><a class="header-anchor" href="#üß™-exercise-1"><span>üß™ Exercise</span></a></h3><h4 id="request-an-llm-with-langchain" tabindex="-1"><a class="header-anchor" href="#request-an-llm-with-langchain"><span>Request an LLM with langchain</span></a></h4><p>Create a Python application that generates humorous motivational quotes for developers based on their name, favorite programming language, and a brief description of their current project or challenge.</p><p><strong>Expected Output</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">Enter your name: Ibrahim</span>
<span class="line">Enter your favorite programming language: kotlin</span>
<span class="line">Enter your current project description: conference app with KMP</span>
<span class="line"></span>
<span class="line">--- Motivational Quote ---</span>
<span class="line">Quote: <span class="token string">&quot;Code like you just ate a burrito... with passion, speed, and a little bit of mess!&quot;</span></span>
<span class="line">Author: Unknown</span>
<span class="line">--------------------------</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">How to start ?</p><ul><li>Open the following <a href="https://colab.research.google.com/drive/1YA6ZhjPiqJkOiPk9Q8UzVYkcvXxJ9kNr?#copy=true" target="_blank" rel="noopener noreferrer">Google Colab notebook</a> and complete the exercise there.</li></ul><p><strong>Steps</strong></p><ol><li>Create a function <code>get_developer_motivation(name, language, project_description)</code> that:</li><li>Takes a developer&#39;s name, their favorite programming language, and a brief description of their current project or challenge as input.</li><li>Uses LangChain to send a request to the LLM to generate a humorous motivational quote.</li><li>Returns a structured response containing the quote, the developer&#39;s name, the programming language, and the project description.</li></ol></div><div class="hint-container tip"><p class="hint-container-title">solution</p><details class="hint-container details"><summary>here</summary><p><a href="https://colab.research.google.com/drive/1oGPjmOlYPwTq19HGpY8PFhsX8OuwPK22?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details></div><h3 id="tools" tabindex="-1"><a class="header-anchor" href="#tools"><span>Tools</span></a></h3><p><a href="https://docs.langchain.com/oss/python/langchain/tools#tools" target="_blank" rel="noopener noreferrer"><code>Function/Tool calling</code></a> is a feature that allows the LLM to call existing functions from your code. It is useful for allowing the LLM to interact wiht external APIs or other models that require function calls. Once a tool function is created, you can register it as a tool within LangChain for being used by the LLM.</p><h4 id="create-a-tool" tabindex="-1"><a class="header-anchor" href="#create-a-tool"><span>Create a tool</span></a></h4><p><strong>With annotated function</strong></p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token decorator annotation punctuation">@tool</span><span class="token punctuation">(</span>name_or_callable<span class="token operator">=</span><span class="token string">&quot;do_something&quot;</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">&quot;this tool does something.&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">some_function</span><span class="token punctuation">(</span>arg<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&quot;output&quot;</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f&quot;Did something with </span><span class="token interpolation"><span class="token punctuation">{</span>arg<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>With Tool class</strong></p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line">a_tool <span class="token operator">=</span> Tool<span class="token punctuation">(</span></span>
<span class="line">    name<span class="token operator">=</span><span class="token string">&quot;do_something&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    description<span class="token operator">=</span><span class="token string">&quot;this tool does something&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    func<span class="token operator">=</span>some_function</span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="bind-tool-to-llm" tabindex="-1"><a class="header-anchor" href="#bind-tool-to-llm"><span>Bind tool to LLM</span></a></h4><p>You can bind the tool to the LLM using the <code>bind_tools</code> method. This allows the LLM to call the tool when needed.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line">llm_with_tools <span class="token operator">=</span> llm<span class="token punctuation">.</span>bind_tools<span class="token punctuation">(</span><span class="token punctuation">[</span>weather_tool<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="handle-tool-calls" tabindex="-1"><a class="header-anchor" href="#handle-tool-calls"><span>Handle tool calls</span></a></h4><p>You can handle tool calls by checking if the response from the LLM includes any tool calls. If a tool call is detected, you can extract the function name and arguments from the tool call and invoke the corresponding tool function.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line">response <span class="token operator">=</span> llm_with_tools<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_data<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">f <span class="token string">&#39;tool_calls&#39;</span> <span class="token keyword">in</span> response<span class="token punctuation">.</span>additional_kwargs<span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># Extract the tool call information</span></span>
<span class="line">        tool_calls <span class="token operator">=</span> response<span class="token punctuation">.</span>additional_kwargs<span class="token punctuation">[</span><span class="token string">&#39;tool_calls&#39;</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">for</span> tool_call <span class="token keyword">in</span> tool_calls<span class="token punctuation">:</span></span>
<span class="line">            <span class="token comment"># Extract the function object and arguments</span></span>
<span class="line">            function_info <span class="token operator">=</span> tool_call<span class="token punctuation">[</span><span class="token string">&#39;function&#39;</span><span class="token punctuation">]</span></span>
<span class="line">            function_name <span class="token operator">=</span> function_info<span class="token punctuation">[</span><span class="token string">&#39;name&#39;</span><span class="token punctuation">]</span></span>
<span class="line">            arguments <span class="token operator">=</span> function_info<span class="token punctuation">[</span><span class="token string">&#39;arguments&#39;</span><span class="token punctuation">]</span></span>
<span class="line">             <span class="token keyword">if</span> function_name <span class="token operator">==</span> <span class="token string">&#39;some_tool&#39;</span><span class="token punctuation">:</span></span>
<span class="line">                <span class="token comment"># Call the tool function with the extracted arguments</span></span>
<span class="line">                tool_response <span class="token operator">=</span> some_tool<span class="token punctuation">(</span><span class="token operator">**</span>arguments<span class="token punctuation">)</span></span>
<span class="line">                <span class="token keyword">return</span> tool_response</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="üß™-exercise-2" tabindex="-1"><a class="header-anchor" href="#üß™-exercise-2"><span>üß™ Exercise</span></a></h3><h4 id="tool-function-calling-request-an-llm-with-tool-function-calling" tabindex="-1"><a class="header-anchor" href="#tool-function-calling-request-an-llm-with-tool-function-calling"><span>Tool/Function calling : Request an LLM with Tool/Function calling</span></a></h4><p>Build a command-line application that fetches weather data for a specified city using LangChain and a public weather API. The application will utilize implicit tool calling to allow the LLM to decide when to call the weather-fetching tool based on user input.</p><h5 id="output" tabindex="-1"><a class="header-anchor" href="#output"><span>Output</span></a></h5><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">Ask about the weather <span class="token punctuation">(</span>e.g., <span class="token string">&#39;Lille, France&#39;</span><span class="token punctuation">)</span>: Paris</span>
<span class="line"></span>
<span class="line">------------------------------------------------------------------------------</span>
<span class="line">The current weather <span class="token keyword">in</span> Paris is: overcast clouds with a temperature of <span class="token number">6.63</span>¬∞C.</span>
<span class="line">------------------------------------------------------------------------------</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">How to start ?</p><ul><li>Sign up for an API key from a weather service provider (e.g., OpenWeatherMap). - You can generate your key <a href="https://home.openweathermap.org/api_keys" target="_blank" rel="noopener noreferrer">here</a></li><li>Here is the API documentation for current weather data: <a href="https://openweathermap.org/current" target="_blank" rel="noopener noreferrer">OpenWeatherMap Current Weather API</a></li></ul><table><thead><tr><th>Endpoint &amp; Description</th><th>Method &amp; URL</th><th>Parameters</th><th>Response</th></tr></thead><tbody><tr><td><strong>Get Current Weather</strong><br>Fetch current weather data for a specified city</td><td>GET <code>https://api.openweathermap.org/data/2.5/weather</code></td><td><code>q</code>: City name (e.g., &quot;Lille&quot;)<br><code>appid</code>: Your API key<br><code>units</code>: Units of measurement (e.g., &quot;metric&quot; for Celsius)</td><td><code>json { &quot;weather&quot;: [{ &quot;description&quot;: &quot;clear sky&quot;, ... }], &quot;main&quot;: { &quot;temp&quot;: 15.5, ... }, ... } </code></td></tr></tbody></table><ul><li>Open the following <a href="https://colab.research.google.com/drive/1dK3C9p9aMbjcK6PHmTKZQYpIcH4A4ZTn?#copy=true" target="_blank" rel="noopener noreferrer">Google Colab notebook</a> and complete the exercise there.</li><li>Define a function <code>fetch_weather(city: str) -&gt; dict</code> that takes a city name as input and returns the weather data as a dictionary. Use the weather API to fetch the data.</li><li>Use the <a href="https://python.langchain.com/docs/concepts/tools/" target="_blank" rel="noopener noreferrer"><code>Tool</code></a> class from LangChain to register the <code>fetch_weather</code> function as a tool.</li><li>Create a prompt template that asks about the weather in a specified city.</li><li>Instantiate the <code>ChatMistralAI</code> model with your Mistral API key.</li><li>Create a chain that combines the prompt template, the chat model, and the registered weather tool.</li><li>Implement a function <code>handle_user_input(city)</code> that: <ul><li>Takes user input for the city name.</li><li>Invokes the chain with the input data.</li><li>Checks if the response includes <a href="https://python.langchain.com/docs/how_to/tool_calling/" target="_blank" rel="noopener noreferrer"><code>tool calls</code></a>.</li><li>Extracts the function name and arguments from the tool call and invokes the weather tool if necessary.</li><li>Returns the weather information or the LLM&#39;s response.</li></ul></li><li>Prompt the user to enter a city name.</li><li>Call the <code>handle_user_input</code> function with the provided city name and display the result.</li></ul></div><div class="hint-container tip"><p class="hint-container-title">Solution</p><details class="hint-container details"><summary>here</summary><p><a href="https://colab.research.google.com/drive/16B84XU5dl2UR5XZkRtnh3MWUK0K5ZBd_?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details></div><h2 id="rag-with-llama-index" tabindex="-1"><a class="header-anchor" href="#rag-with-llama-index"><span>RAG with llama-index</span></a></h2><p><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/" target="_blank" rel="noopener noreferrer"><strong>llama-index</strong></a> is a powerful tool for building and deploying RAG (Retrieval Augmented Generation) applications. It provides a simple and efficient way to integrate LLMs into your applications, allowing you to retrieve relevant information from a large knowledge base and use it to generate responses. RAG is a technique that leverages the power of LLMs to augment human-generated content.</p><h3 id="rag-over-unstructured-documents" tabindex="-1"><a class="header-anchor" href="#rag-over-unstructured-documents"><span>RAG over Unstructured Documents</span></a></h3><p>Unstructured documents are a common source of information for RAG applications. These documents can be in various formats, such as text, PDF, HTML, or images. LlamaIndex provides tools for indexing and querying unstructured documents, enabling you to build powerful RAG applications that can retrieve information from a large corpus of documents.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line">documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_files<span class="token operator">=</span><span class="token punctuation">[</span>fn<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">index <span class="token operator">=</span> SummaryIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> settings<span class="token operator">=</span>settings<span class="token punctuation">)</span></span>
<span class="line">query_engine <span class="token operator">=</span> index<span class="token punctuation">.</span>as_query_engine<span class="token punctuation">(</span>response_mode<span class="token operator">=</span><span class="token string">&quot;tree_summarize&quot;</span><span class="token punctuation">,</span> llm<span class="token operator">=</span>llm<span class="token punctuation">)</span></span>
<span class="line">response <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">&quot;&lt;your_query_here&gt;&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="üß™-exercise-3" tabindex="-1"><a class="header-anchor" href="#üß™-exercise-3"><span>üß™ Exercise</span></a></h3><h4 id="querying-on-unstructured-documents" tabindex="-1"><a class="header-anchor" href="#querying-on-unstructured-documents"><span>Querying on Unstructured Documents</span></a></h4><p>Create a Python application that provide a txt document containings a list of application comments and make sentiment analysis on it with <code>llama-index</code>.</p><p>Your customer review txt file :</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code class="language-text"><span class="line">Review 1: I was very disappointed with the product. It did not meet my expectations.</span>
<span class="line">Review 2: The service was excellent! I highly recommend this company.</span>
<span class="line">Review 3: I had a terrible experience. The product was faulty, and the customer support was unhelpful.</span>
<span class="line">Review 4: I am extremely satisfied with my purchase. The quality is outstanding.</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Expected Shell Output:</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line">Saving customer_reviews.txt to customer_reviews <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>.txt</span>
<span class="line">User uploaded <span class="token function">file</span> <span class="token string">&quot;customer_reviews (4).txt&quot;</span> with length <span class="token number">338</span> bytes</span>
<span class="line">The customers&#39; experiences with the company and its products vary. Some have had positive experiences, such as excellent <span class="token function">service</span> and high-quality products, <span class="token keyword">while</span> others have encountered issues with faulty products and unhelpful customer support.</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">How to start ?</p><ul><li>Open the following <a href="https://colab.research.google.com/drive/1_1CpaIHiu3bfSlpGamhOtTH-SRCpSB2q?#copy=true" target="_blank" rel="noopener noreferrer">Google Colab notebook</a> and complete the exercise there.</li><li>Create a text file named <code>customer_reviews.txt</code> containing the provided customer reviews.</li><li>Use colab&#39;s file upload feature to upload the <code>customer_reviews.txt</code> file to your Colab environment.</li><li>Load the document using <code>SimpleDirectoryReader</code> from <code>llama_index</code>.</li><li>Create a <code>SummaryIndex</code> from the loaded document.</li><li>Instantiate a query engine using the index and the LLM.</li><li>Implement a function <code>analyze_sentiment()</code> that: <ul><li>Queries the index for sentiment analysis of the customer reviews.</li><li>Returns the sentiment analysis result.</li></ul></li><li>Call the <code>analyze_sentiment()</code> function and display the result.</li></ul></div><div class="hint-container tip"><p class="hint-container-title">Solution</p><details class="hint-container details"><summary>here</summary><p><a href="https://colab.research.google.com/drive/1HRVqcYEl2RLQDQ8l4NoGcdxiqU-6CgJa?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details></div><h3 id="question-answering-qa-over-structured-data-mysql" tabindex="-1"><a class="header-anchor" href="#question-answering-qa-over-structured-data-mysql"><span>Question Answering (QA) over Structured Data (MySQL)</span></a></h3><p>Structured Data is another common source of information for RAG applications. This data is typically stored in databases or spreadsheets and can be queried using SQL or other query languages. LlamaIndex provides tools for connecting LLMs to databases and querying structured data, allowing you to build RAG applications that can retrieve information from databases.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token comment">#The database library used in this example is SQLAlchemy</span></span>
<span class="line">sql_database <span class="token operator">=</span> SQLDatabase<span class="token punctuation">(</span>engine<span class="token punctuation">,</span> include_tables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;books&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">query_engine <span class="token operator">=</span> NLSQLTableQueryEngine<span class="token punctuation">(</span></span>
<span class="line">    sql_database<span class="token operator">=</span>sql_database<span class="token punctuation">,</span></span>
<span class="line">    tables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;books&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span></span>
<span class="line">    embed_model<span class="token operator">=</span>embed_model<span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">&quot;Who wrote &#39;To Kill a Mockingbird&#39;?&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="üß™-exercise-4" tabindex="-1"><a class="header-anchor" href="#üß™-exercise-4"><span>üß™ Exercise</span></a></h3><h5 id="rag-querying-sql-databases-with-natural-language" tabindex="-1"><a class="header-anchor" href="#rag-querying-sql-databases-with-natural-language"><span>RAG : Querying SQL Databases with Natural Language</span></a></h5><p>Create a Python application that initializes a list of languages and their creators with <code>sqlalchemy</code> and requests the LLM to retrieve the creators of a language. The LLM should be able to understand the context and retrieve the relevant information from the database.</p><p><strong>Expected Shell Output:</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code class="language-bash"><span class="line"><span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Python&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Guido van Rossum&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1991</span></span>
<span class="line">    <span class="token punctuation">}</span>,</span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;JavaScript&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Brendan Eich&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1995</span></span>
<span class="line">    <span class="token punctuation">}</span>,</span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Java&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;James Gosling&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1995</span></span>
<span class="line">    <span class="token punctuation">}</span>,</span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;C++&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Bjarne Stroustrup&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1985</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">]</span></span>
<span class="line">Guido van Rossum created Python <span class="token keyword">in</span> <span class="token number">1991</span>.</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">How to start ?</p><ul><li>Open the following <a href="https://colab.research.google.com/drive/1Gvzue-0s4NYvKIKFDNtj6y_a1wdNSWbO?#copy=true" target="_blank" rel="noopener noreferrer">Google Colab notebook</a> and complete the exercise there.</li><li>Define a SQLAlchemy model for the programming languages table.</li><li>Initialize the database with a list of programming languages and their creators.</li><li>Create a <code>SQLDatabase</code> instance using the SQLAlchemy engine.</li><li>Instantiate the <code>NLSQLTableQueryEngine</code> with the SQL database and the LLM.</li><li>Implement a function <code>get_language_creator(language_name)</code> that: <ul><li>Takes a programming language name as input.</li><li>Uses the query engine to retrieve the creator of the specified language.</li><li>Returns the creator&#39;s name and the year the language was created.</li></ul></li><li>Prompt the user to enter a programming language name.</li><li>Call the <code>get_language_creator</code> function with the provided language name and display the result.</li></ul></div><div class="hint-container tip"><p class="hint-container-title">Solution</p><details class="hint-container details"><summary>here</summary><p><a href="https://colab.research.google.com/drive/1osoFUAxRbZayftaTlCtJIqlWlj_0c3sQ?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details></div><h2 id="embeddings" tabindex="-1"><a class="header-anchor" href="#embeddings"><span>Embeddings</span></a></h2><p>Embeddings are numerical representations of words, phrases, or entire documents in a continuous vector space. They capture semantic relationships between different pieces of text, allowing LLMs to understand context and meaning more effectively. An Embedding is the specialization of a Vector in the context of language models.</p><p>It can be useful to store embeddings in a vector database to enable efficient similarity search and retrieval of relevant information and have cost effective solutions for large scale applications.</p><p>Contesxt aware frameworks like LangChain provide easy to use APIs to interact with embedding endpoints of LLM providers.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code class="language-python"><span class="line"><span class="token keyword">from</span> langchain_mistralai<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> MistralAIEmbeddings</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="üß™-exercises" tabindex="-1"><a class="header-anchor" href="#üß™-exercises"><span>üß™ Exercises</span></a></h2><h4 id="exercice-1-use-langchain-to-request-mistral-ai-api-embedding-endpoint-to-get-the-embedding-of-a-text-prompt" tabindex="-1"><a class="header-anchor" href="#exercice-1-use-langchain-to-request-mistral-ai-api-embedding-endpoint-to-get-the-embedding-of-a-text-prompt"><span>Exercice 1- Use langchain to request Mistral AI API embedding endpoint to get the embedding of a text prompt</span></a></h4><div class="hint-container warning"><p class="hint-container-title">How to start ?</p><ul><li>Open the following <a href="https://colab.research.google.com/drive/1O5cnBQdX1CpvKL8_IkHfkFXlhYwsGXMy?#copy=true" target="_blank" rel="noopener noreferrer">Google Colab notebook</a> and complete the exercise there.</li><li>Install the <code>langchain_mistralai</code> package in your Colab environment.</li><li>Create a <code>MistralAIEmbeddings</code> object with your Mistral API key.</li><li>Implement a function <code>get_text_embedding(text)</code> that: <ul><li>Takes a text prompt as input.</li><li>Uses the <code>MistralAIEmbeddings</code> object to get the embedding of the text.</li><li>Returns the embedding as a list of floats.</li></ul></li><li>Call the <code>get_text_embedding</code> function with a sample text prompt and display the embedding.</li></ul></div><div class="hint-container tip"><p class="hint-container-title">Solution</p><details class="hint-container details"><summary>here</summary><p><a href="https://colab.research.google.com/drive/1oGPjmOlYPwTq19HGpY8PFhsX8OuwPK22?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details></div><h4 id="exercice-2-let-s-use-chaining-to-create-a-chain-that-compares-the-embeddings" tabindex="-1"><a class="header-anchor" href="#exercice-2-let-s-use-chaining-to-create-a-chain-that-compares-the-embeddings"><span>Exercice 2 - Let&#39;s use chaining to create a chain that compares the embeddings.</span></a></h4><p>You have a json file with a list of FAQ questions and answers. Let&#39;s request the Mistral AI API to get the embedding of a question and compare it with the embeddings of the FAQ questions to find the most similar one. Then return the question of the FAQ that is the most similar to the question asked to get the final answer from the LLM.</p><p>Here is the schema :</p><div>
flowchart TD
A[JSON FAQs
Questions &amp; Answers] --&gt; B[Convert to List]
B --&gt; C[LLM Embedding
Request]
C --&gt; D((FAQ
Embedding))
E[User Prompt
Can I get refund?] --&gt; F[LLM Embedding
Request]
F --&gt; G((User
Embedding))
D --&gt; H[Cosine
Comparison]
G --&gt; H
H --&gt; I((Closest FAQ
Match))
I --&gt; J[LLM Final
Response]
classDef default fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
classDef circle fill:#bbdefb,stroke:#1565c0,stroke-width:2px,color:#000
class D,G,I circle
</div><div class="hint-container warning"><p class="hint-container-title">How to start ?</p><ul><li>Open the following <a href="https://colab.research.google.com/drive/1Mdw_Ac0raY_vZeTjH4U_436J42cyHmoi?#copy=true" target="_blank" rel="noopener noreferrer">Google Colab notebook</a> and complete the exercise there.</li><li>Create a JSON file named <code>faqs.json</code> containing a list of FAQ questions and answers.</li><li>Load the FAQ data from the JSON file and convert it to a list of questions and answers.</li><li>Create a <code>MistralAIEmbeddings</code> object with your Mistral API key.</li><li>Implement a function <code>get_most_similar_faq(user_question)</code> that: <ul><li>Takes a user question as input.</li><li>Uses the <code>MistralAIEmbeddings</code> object to get the embedding of the user question.</li><li>Compares the user question embedding with the FAQ question embeddings using cosine similarity.</li><li>Returns the most similar FAQ question and its answer.</li></ul></li><li>Call the <code>get_most_similar_faq</code> function with a sample user question and display the result.</li></ul></div><div class="hint-container tip"><p class="hint-container-title">Solution</p><details class="hint-container details"><summary>here</summary><p><a href="https://colab.research.google.com/drive/1vcAbbjEuADzLKo9xxwXu6QY8f1-Vnz4L?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details></div><h2 id="vector-databases-soon" tabindex="-1"><a class="header-anchor" href="#vector-databases-soon"><span>Vector databases (Soon)</span></a></h2><p>A vector database is a specialized database designed to store and retrieve high-dimensional vectors efficiently. It is particularly useful for applications involving similarity search, such as image recognition, recommendation systems, and natural language processing.</p><h3 id="usage-of-chroma" tabindex="-1"><a class="header-anchor" href="#usage-of-chroma"><span>Usage of Chroma</span></a></h3><p>Chroma is a vector database that allows you to store and query vectors of data. Lanchain provides a simple and efficient way to integrate <a href="https://www.trychroma.com/" target="_blank" rel="noopener noreferrer">Chroma</a> into your applications, allowing you to store and query vectors of data using LLMs.</p><p>Please refer to the <a href="https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/" target="_blank" rel="noopener noreferrer">Langchain vector documentation</a> for more information on how to use Chroma.</p><h2 id="üìñ-further-readings" tabindex="-1"><a class="header-anchor" href="#üìñ-further-readings"><span>üìñ Further readings</span></a></h2></div><!--[--><!--]--></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link label" href="https://github.com/worldline/learning-ai/activity/edit/main/5.services/README.md" aria-label="Edit this page" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><svg class="edit-icon" viewbox="0 0 1024 1024"><g fill="currentColor"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></g></svg><!--]--><!--]-->Edit this page<!--[--><!--[--><!--]--><!--]--></a></div><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><time class="meta-item-info" datetime="2025-12-16T10:59:31.000Z" data-allow-mismatch>12/16/25, 10:59 AM</time></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: brah.gharbi@gmail.com">Ibrahim Gharbi</span><!--[-->, <!--]--><!--]--><!--[--><span class="contributor" title="email: brah.gharbi@gmail.com">Brah</span><!--[-->, <!--]--><!--]--><!--[--><span class="contributor" title="email: 1958676+yostane@users.noreply.github.com">yostane</span><!--[-->, <!--]--><!--]--><!--[--><span class="contributor" title="email: sylvain.pollet.villard@gmail.com">Sylvain Pollet-Villard</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/learning-ai/4.assistant/" aria-label="Code Assistants in IDEs"><!--[--><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span class="external-link">Code Assistants in IDEs</span></div><!--]--></a><a class="route-link auto-link next" href="/learning-ai/6.agentic/" aria-label="Agentic AI for services"><!--[--><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span class="external-link">Agentic AI for services</span></div><!--]--></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/learning-ai/assets/app-DmbIGF3-.js" defer></script>
  </body>
</html>
